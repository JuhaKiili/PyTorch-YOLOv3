- step:
    name: train model
    image: floydhub/pytorch:1.1.0-gpu.cuda9cudnn7-py3.45
    command:
      - git clone https://github.com/pdollar/coco
      - mkdir coco/images; mkdir coco/labels
      - cd /valohai/inputs/training-set-images && unzip train2014-redux.zip
      # after extraction we want images to end up at /valohai/repository/coco/images/train2014/<img-name>.jpg
      - ln -s /valohai/inputs/training-set-images/train2014-redux/train2014 /valohai/repository/coco/images/train2014
      - cd /valohai/inputs/training-set-labels && tar -xzf labels.tgz
      - ln -s /valohai/inputs/training-set-labels/labels/train2014 /valohai/repository/coco/labels/train2014
      - cd /valohai/inputs/training-set-instances && unzip instances_train-val2014.zip
      - ln -s /valohai/inputs/training-set-instances/annotations /valohai/repository/coco/annotations
      - ln -s /valohai/inputs/training-set-images-list/images-list.txt /valohai/repository/coco/images-list.txt
      - cd /valohai/repository && pip install -r requirements.txt
      - python3 train.py --data_config config/coco.data

- step:
    name: batch inference
    image: floydhub/pytorch:1.1.0-gpu.cuda9cudnn7-py3.45
    command:
      - cp /valohai/inputs/darknet-weights/darknet53.conv.74 /valohai/repository/weights/
      - cp /valohai/inputs/yolov3-weights/yolov3.weights /valohai/repository/weights/
      - python3 detect.py --image_folder data/samples
      - mkdir /valohai/outputs/images-detected
      - cp output/* /valohai/outputs/images-detected
    inputs:
      - name: yolov3-weights
        default: datum://016d3ed2-d3de-1f51-ddd7-3d401840e568
      - name: darknet-weights
        default: datum://016d3ed4-a1ff-ea83-7a41-c8fdae8d3eac
