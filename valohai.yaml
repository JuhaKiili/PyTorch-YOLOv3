- step:
    name: train model
    image: floydhub/pytorch:1.1.0-gpu.cuda9cudnn7-py3.45
    command:
      - git clone https://github.com/pdollar/coco
      - mkdir coco/images; mkdir coco/labels
      - cd /valohai/inputs/training-set-images && unzip train2014-redux.zip
      # after extraction we want images to end up at /valohai/repository/coco/images/train2014/<img-name>.jpg
      - ln -s /valohai/inputs/training-set-images/train2014-redux/train2014 /valohai/repository/coco/images/train2014
      - cd /valohai/inputs/training-set-labels && tar -xzf labels.tgz
      - ln -s /valohai/inputs/training-set-labels/labels/train2014 /valohai/repository/coco/labels/train2014
      - cd /valohai/inputs/training-set-instances && unzip instances_train-val2014.zip
      - ln -s /valohai/inputs/training-set-instances/annotations /valohai/repository/coco/annotations
      - ln -s /valohai/inputs/training-set-images-list/images-list.txt /valohai/repository/coco/images-list.txt
      - cd /valohai/repository && pip install -r requirements.txt
      - ls -la /valohai/repository/coco/labels
      - ls -la /valohai/repository/coco/labels/train2014/COCO_train2014_000000000671.txt
      - python3 train.py --data_config config/coco.data
    inputs:
      - name: training-set-images
        default: datum://016d2046-193a-de87-ef3e-f90c449f60fa
      - name: training-set-labels
        default: datum://016d1b71-f37d-1692-7528-efa879b573c6
      - name: training-set-instances
        default: datum://016d1b89-97c5-bfe6-28bf-b46469f27436
      - name: training-set-images-list
        default: datum://016d2025-3cf2-4e4e-fc27-309af7efde46
